#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æ¡£è½¬æ¢å·¥å…·ï¼šå°† DOC/PDF è½¬æ¢ä¸º Markdown æ ¼å¼
æ”¯æŒå±‚çº§ç»“æ„è¯†åˆ«å’Œ YAML å‰å¯¼ä¿¡æ¯ç”Ÿæˆ
"""

import os
import re
import sys
from pathlib import Path
from datetime import datetime
import frontmatter
import yaml

# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
try:
    from docx import Document
    from docx.shared import Inches
    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
except ImportError:
    print("è¯·å®‰è£… python-docx: pip install python-docx")
    sys.exit(1)

try:
    import pdfplumber
    import PyPDF2
except ImportError:
    print("è¯·å®‰è£… PDF å¤„ç†åº“: pip install pdfplumber PyPDF2")
    sys.exit(1)


class DocumentConverter:
    """æ–‡æ¡£è½¬æ¢å™¨ä¸»ç±»"""
    
    def __init__(self, output_dir="converted_markdown"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
    def extract_metadata_from_filename(self, filename):
        """ä»æ–‡ä»¶åæå–å…ƒæ•°æ®"""
        name = Path(filename).stem
        metadata = {
            'title': name,
            'filename': filename,
            'converted_at': datetime.now().isoformat(),
            'source_type': 'unknown'
        }
        
        # æå–ä¸“ä¸šä¿¡æ¯
        if 'ä¼šè®¡' in name:
            metadata['major'] = 'ä¼šè®¡'
        elif 'ä¿¡ç®¡' in name:
            metadata['major'] = 'ä¿¡æ¯ç®¡ç†'
        elif 'å·¥å•†' in name:
            metadata['major'] = 'å·¥å•†ç®¡ç†'
        elif 'è®¡ç§‘' in name or 'CS' in name:
            metadata['major'] = 'è®¡ç®—æœºç§‘å­¦'
        elif 'é€šä¿¡' in name:
            metadata['major'] = 'é€šä¿¡å·¥ç¨‹'
        elif 'ç¯å¢ƒ' in name:
            metadata['major'] = 'ç¯å¢ƒå·¥ç¨‹'
        elif 'æ•°åª’' in name:
            metadata['major'] = 'æ•°å­—åª’ä½“'
        
        # æå–å¹´ä»½
        year_match = re.search(r'(20\d{2})', name)
        if year_match:
            metadata['year'] = year_match.group(1)
        
        # æå–å­¦ç”Ÿå§“åï¼ˆé€šå¸¸åœ¨"é£è·ƒæ‰‹å†Œ-"åé¢ï¼‰
        name_match = re.search(r'é£è·ƒæ‰‹å†Œ[-_]?(.+)', name)
        if name_match:
            metadata['student_name'] = name_match.group(1).replace('-', ' ').replace('_', ' ')
        
        return metadata
    
    def convert_docx_to_markdown(self, docx_path):
        """å°† DOCX æ–‡ä»¶è½¬æ¢ä¸º Markdown"""
        try:
            doc = Document(docx_path)
            markdown_content = []
            
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue
                
                # æ£€æµ‹æ ‡é¢˜çº§åˆ«ï¼ˆåŸºäºå­—ä½“å¤§å°å’Œæ ·å¼ï¼‰
                if paragraph.style.name.startswith('Heading'):
                    level = int(paragraph.style.name.split()[-1])
                    markdown_content.append(f"{'#' * level} {text}")
                elif paragraph.style.name == 'Title':
                    markdown_content.append(f"# {text}")
                elif paragraph.style.name == 'Subtitle':
                    markdown_content.append(f"## {text}")
                elif len(text) > 50 and not text.endswith(('.', 'ã€‚', '!', 'ï¼', '?', 'ï¼Ÿ')):
                    # å¯èƒ½æ˜¯æ ‡é¢˜ï¼Œä½¿ç”¨äºŒçº§æ ‡é¢˜
                    markdown_content.append(f"## {text}")
                else:
                    markdown_content.append(text)
                
                markdown_content.append("")  # æ·»åŠ ç©ºè¡Œ
            
            # å¤„ç†è¡¨æ ¼
            for table in doc.tables:
                markdown_content.append(self._convert_table_to_markdown(table))
                markdown_content.append("")
            
            return "\n".join(markdown_content)
            
        except Exception as e:
            print(f"è½¬æ¢ DOCX æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return f"# è½¬æ¢é”™è¯¯\n\næ— æ³•è¯»å–æ–‡ä»¶: {docx_path}\né”™è¯¯: {str(e)}"
    
    def convert_pdf_to_markdown(self, pdf_path):
        """å°† PDF æ–‡ä»¶è½¬æ¢ä¸º Markdown - åŸºäºè§†è§‰ç»“æ„åˆ†æ"""
        try:
            markdown_content = []
            
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    # æå–æ–‡æœ¬å’Œå­—ä½“ä¿¡æ¯
                    text_objects = page.chars
                    text_lines = page.extract_text_simple().split('\n')
                    
                    # åˆ†æå­—ä½“å¤§å°åˆ†å¸ƒ
                    font_sizes = [char['size'] for char in text_objects if char['size']]
                    if font_sizes:
                        avg_font_size = sum(font_sizes) / len(font_sizes)
                        large_font_threshold = avg_font_size * 1.2
                        small_font_threshold = avg_font_size * 0.8
                    else:
                        avg_font_size = 12
                        large_font_threshold = 14
                        small_font_threshold = 10
                    
                    # å¤„ç†æ¯ä¸€è¡Œæ–‡æœ¬
                    processed_lines = self._process_text_lines(text_lines, text_objects, 
                                                            large_font_threshold, small_font_threshold)
                    markdown_content.extend(processed_lines)
                    
                    if page_num < len(pdf.pages):
                        markdown_content.append("\n---\n")
            
            return "\n".join(markdown_content)
            
        except Exception as e:
            print(f"è½¬æ¢ PDF æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return f"# è½¬æ¢é”™è¯¯\n\næ— æ³•è¯»å–æ–‡ä»¶: {pdf_path}\né”™è¯¯: {str(e)}"
    
    def _process_text_lines(self, text_lines, text_objects, large_font_threshold, small_font_threshold):
        """å¤„ç†æ–‡æœ¬è¡Œï¼ŒåŸºäºè§†è§‰ç»“æ„åˆ†æ"""
        processed_lines = []
        current_paragraph = []
        in_list = False
        
        for line in text_lines:
            line = line.strip()
            if not line:
                # ç©ºè¡Œï¼šç»“æŸå½“å‰æ®µè½
                if current_paragraph:
                    processed_lines.extend(self._finalize_paragraph(current_paragraph, in_list))
                    current_paragraph = []
                    in_list = False
                processed_lines.append('')
                continue
            
            # åˆ†æè¡Œçš„ç‰¹å¾
            line_features = self._analyze_line_features(line, text_objects)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜
            if self._is_visual_title(line, line_features, large_font_threshold):
                # ç»“æŸå½“å‰æ®µè½
                if current_paragraph:
                    processed_lines.extend(self._finalize_paragraph(current_paragraph, in_list))
                    current_paragraph = []
                    in_list = False
                
                # æ·»åŠ æ ‡é¢˜
                title_level = self._determine_title_level(line)
                processed_lines.append(f"{'#' * title_level} {line}")
                processed_lines.append('')
            elif self._is_list_item(line):
                # åˆ—è¡¨é¡¹
                if current_paragraph and not in_list:
                    processed_lines.extend(self._finalize_paragraph(current_paragraph, False))
                    current_paragraph = []
                
                in_list = True
                processed_lines.append(f"- {line}")
            else:
                # æ™®é€šæ–‡æœ¬
                if in_list:
                    # ç»“æŸåˆ—è¡¨
                    processed_lines.append('')
                    in_list = False
                
                current_paragraph.append(line)
        
        # å¤„ç†æœ€åä¸€ä¸ªæ®µè½
        if current_paragraph:
            processed_lines.extend(self._finalize_paragraph(current_paragraph, in_list))
        
        return processed_lines
    
    def _analyze_line_features(self, line, text_objects):
        """åˆ†æè¡Œçš„è§†è§‰ç‰¹å¾"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è§†è§‰åˆ†æ
        return {
            'length': len(line),
            'starts_with_number': bool(re.match(r'^\d+[\.\)]', line)),
            'starts_with_bullet': line.startswith(('â€¢', 'Â·', '-', '*')),
            'ends_with_colon': line.endswith(('ï¼š', ':')),
            'is_question': line.endswith('?') or line.endswith('ï¼Ÿ'),
            'is_short': len(line) < 50
        }
    
    def _is_visual_title(self, line, features, large_font_threshold):
        """åŸºäºè§†è§‰ç‰¹å¾åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜"""
        # æ˜ç¡®çš„æ ‡é¢˜æ¨¡å¼
        title_patterns = [
            r'^å‰è¨€$', r'^ä¸ªäººæƒ…å†µ$', r'^ç”³è¯·å‡†å¤‡$', r'^ç»éªŒæ€»ç»“$',
            r'^æˆ‘åº”è¯¥.*\?$', r'^å¦‚ä½•.*\?$', r'^.*è§„åˆ’.*\?$',
            r'^GPA[:ï¼š]', r'^é›…æ€[:ï¼š]', r'^æ‰˜ç¦[:ï¼š]', r'^GRE[:ï¼š]',
            r'^å»å‘[:ï¼š]', r'^ç¡¬èƒŒæ™¯[:ï¼š]', r'^è½¯èƒŒæ™¯[:ï¼š]'
        ]
        
        for pattern in title_patterns:
            if re.match(pattern, line):
                return True
        
        # çŸ­å¥ä¸”ä»¥å†’å·ç»“å°¾
        if features['is_short'] and features['ends_with_colon']:
            return True
        
        # æ•°å­—ç¼–å·çš„æ ‡é¢˜
        if features['starts_with_number'] and features['is_short']:
            return True
        
        return False
    
    def _is_list_item(self, line):
        """åˆ¤æ–­æ˜¯å¦ä¸ºåˆ—è¡¨é¡¹"""
        return (line.startswith(('â€¢', 'Â·', '-', '*')) or 
                re.match(r'^\d+[\.\)]\s', line) or
                re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.]\s', line))
    
    def _determine_title_level(self, line):
        """ç¡®å®šæ ‡é¢˜çº§åˆ«"""
        # ä¸»è¦ç« èŠ‚
        if re.match(r'^(å‰è¨€|ä¸ªäººæƒ…å†µ|ç”³è¯·å‡†å¤‡|ç»éªŒæ€»ç»“|æœ€åæƒ³è¯´çš„è¯)$', line):
            return 1
        
        # é—®é¢˜æ ‡é¢˜
        if re.match(r'^æˆ‘åº”è¯¥.*\?$', line):
            return 1
        
        # å…·ä½“ä¸»é¢˜
        if re.match(r'^(GPA|é›…æ€|æ‰˜ç¦|GRE|å»å‘|ç¡¬èƒŒæ™¯|è½¯èƒŒæ™¯)[:ï¼š]', line):
            return 2
        
        # ç¼–å·æ ‡é¢˜
        if re.match(r'^\d+\.\s', line):
            return 2
        
        # é»˜è®¤äºŒçº§æ ‡é¢˜
        return 2
    
    def _finalize_paragraph(self, paragraph_lines, was_list):
        """å®Œæˆæ®µè½å¤„ç†"""
        if not paragraph_lines:
            return []
        
        # åˆå¹¶æ®µè½è¡Œ
        paragraph_text = ' '.join(paragraph_lines)
        
        # æ¸…ç†å¤šä½™çš„æ ‡ç‚¹ç¬¦å·
        paragraph_text = re.sub(r'\s+([ï¼Œã€‚ï¼›ï¼š])', r'\1', paragraph_text)
        paragraph_text = re.sub(r'([ï¼Œã€‚ï¼›ï¼š])\s+', r'\1 ', paragraph_text)
        
        return [paragraph_text, '']
    
    def _detect_title_level(self, line, section_stack):
        """æ™ºèƒ½æ£€æµ‹æ ‡é¢˜å±‚çº§"""
        # é£è·ƒæ‰‹å†Œç‰¹æœ‰çš„æ ‡é¢˜æ¨¡å¼
        title_patterns = {
            # ä¸€çº§æ ‡é¢˜ï¼šä¸»è¦ç« èŠ‚
            1: [
                r'^å‰è¨€$', r'^ä¸ªäººæƒ…å†µ$', r'^ç”³è¯·å‡†å¤‡$', r'^ç”³è¯·è¿‡ç¨‹$', 
                r'^ç»éªŒæ€»ç»“$', r'^å»ºè®®$', r'^æœ€åæƒ³è¯´çš„è¯$', r'^ç»“è¯­$',
                r'^æˆ‘åº”è¯¥.*\?$', r'^å¦‚ä½•.*\?$', r'^.*è§„åˆ’.*\?$'
            ],
            # äºŒçº§æ ‡é¢˜ï¼šå…·ä½“ä¸»é¢˜
            2: [
                r'^GPA[:ï¼š]', r'^é›…æ€[:ï¼š]', r'^æ‰˜ç¦[:ï¼š]', r'^GRE[:ï¼š]', 
                r'^å»å‘[:ï¼š]', r'^ç¡¬èƒŒæ™¯[:ï¼š]', r'^è½¯èƒŒæ™¯[:ï¼š]', r'^è¯­è¨€[:ï¼š]',
                r'^å®ä¹ [:ï¼š]', r'^é¡¹ç›®[:ï¼š]', r'^ç§‘ç ”[:ï¼š]', r'^CV[:ï¼š]', r'^PS[:ï¼š]',
                r'^ç¬”é¢[:ï¼š]', r'^Tips[:ï¼š]', r'^æ—¶é—´çº¿[:ï¼š]', r'^æ—¶é—´è§„åˆ’[:ï¼š]',
                r'^[0-9]+\.\s*[^ã€‚]+$',  # æ•°å­—ç¼–å·çš„æ ‡é¢˜
                r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.]\s*[^ã€‚]+$'  # ä¸­æ–‡ç¼–å·
            ],
            # ä¸‰çº§æ ‡é¢˜ï¼šç»†åˆ†å†…å®¹
            3: [
                r'^[0-9]+\.[0-9]+\s*[^ã€‚]+$',  # äºŒçº§ç¼–å·
                r'^[a-zA-Z]\.\s*[^ã€‚]+$',  # å­—æ¯ç¼–å·
                r'^[â€¢Â·]\s*[^ã€‚]+$'  # é¡¹ç›®ç¬¦å·
            ]
        }
        
        # æ£€æŸ¥å„ç§æ ‡é¢˜æ¨¡å¼
        for level, patterns in title_patterns.items():
            for pattern in patterns:
                if re.match(pattern, line):
                    return level
        
        # ç‰¹æ®Šå¤„ç†ï¼šçŸ­å¥ä¸”ä»¥å†’å·ç»“å°¾
        if len(line) < 30 and line.endswith(('ï¼š', ':')):
            return 2
        
        # ç‰¹æ®Šå¤„ç†ï¼šå…¨å¤§å†™æˆ–é¦–å­—æ¯å¤§å†™çš„çŸ­å¥
        if len(line) < 50 and (line.isupper() or line.istitle()):
            return 2
        
        # ä¸æ˜¯æ ‡é¢˜
        return 0
    
    def _is_title(self, line):
        """ç®€å•åˆ¤æ–­æ˜¯å¦ä¸ºæ ‡é¢˜ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        return self._detect_title_level(line, []) > 0
    
    def _convert_table_to_markdown(self, table):
        """å°†è¡¨æ ¼è½¬æ¢ä¸º Markdown æ ¼å¼"""
        markdown_table = []
        
        for i, row in enumerate(table.rows):
            row_data = []
            for cell in row.cells:
                cell_text = cell.text.strip().replace('\n', ' ')
                row_data.append(cell_text)
            
            markdown_table.append("| " + " | ".join(row_data) + " |")
            
            # æ·»åŠ è¡¨å¤´åˆ†éš”çº¿
            if i == 0:
                separator = "| " + " | ".join(["---"] * len(row_data)) + " |"
                markdown_table.append(separator)
        
        return "\n".join(markdown_table)
    
    def add_yaml_frontmatter(self, content, metadata):
        """æ·»åŠ  YAML å‰å¯¼ä¿¡æ¯"""
        yaml_content = yaml.dump(metadata, default_flow_style=False, allow_unicode=True)
        return f"---\n{yaml_content}---\n\n{content}"
    
    def _post_process_content(self, content):
        """åå¤„ç†å†…å®¹ï¼Œä¼˜åŒ–ç»“æ„"""
        lines = content.split('\n')
        processed_lines = []
        i = 0
        
        while i < len(lines):
            line = lines[i].strip()
            
            if not line:
                processed_lines.append('')
                i += 1
                continue
            
            # å¤„ç†è¿ç»­çš„ç©ºè¡Œ
            if processed_lines and processed_lines[-1] == '' and line == '':
                i += 1
                continue
            
            # å¤„ç†æ ‡é¢˜åçš„ç©ºè¡Œ
            if line.startswith('#'):
                processed_lines.append(line)
                # ç¡®ä¿æ ‡é¢˜åæœ‰é€‚å½“çš„ç©ºè¡Œ
                if i + 1 < len(lines) and lines[i + 1].strip():
                    processed_lines.append('')
            else:
                processed_lines.append(line)
            
            i += 1
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        result_lines = []
        prev_empty = False
        
        for line in processed_lines:
            if line == '':
                if not prev_empty:
                    result_lines.append(line)
                prev_empty = True
            else:
                result_lines.append(line)
                prev_empty = False
        
        return '\n'.join(result_lines)
    
    def convert_file(self, file_path):
        """è½¬æ¢å•ä¸ªæ–‡ä»¶"""
        file_path = Path(file_path)
        if not file_path.exists():
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        
        # æå–å…ƒæ•°æ®
        metadata = self.extract_metadata_from_filename(file_path.name)
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è½¬æ¢æ–¹æ³•
        if file_path.suffix.lower() in ['.docx', '.doc']:
            metadata['source_type'] = 'docx'
            content = self.convert_docx_to_markdown(file_path)
        elif file_path.suffix.lower() == '.pdf':
            metadata['source_type'] = 'pdf'
            content = self.convert_pdf_to_markdown(file_path)
        else:
            print(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.suffix}")
            return None
        
        # åå¤„ç†å†…å®¹
        content = self._post_process_content(content)
        
        # æ·»åŠ  YAML å‰å¯¼ä¿¡æ¯
        full_content = self.add_yaml_frontmatter(content, metadata)
        
        # ä¿å­˜è½¬æ¢åçš„æ–‡ä»¶
        output_filename = file_path.stem + '.md'
        output_path = self.output_dir / output_filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        print(f"âœ… è½¬æ¢å®Œæˆ: {file_path.name} -> {output_filename}")
        return output_path
    
    def batch_convert(self, directory_path, recursive=True):
        """æ‰¹é‡è½¬æ¢ç›®å½•ä¸­çš„æ–‡ä»¶"""
        directory_path = Path(directory_path)
        if not directory_path.exists():
            print(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
            return
        
        supported_extensions = ['.docx', '.doc', '.pdf']
        converted_files = []
        failed_files = []
        
        # æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
        if recursive:
            files = []
            for ext in supported_extensions:
                files.extend(directory_path.rglob(f"*{ext}"))
        else:
            files = []
            for ext in supported_extensions:
                files.extend(directory_path.glob(f"*{ext}"))
        
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶éœ€è¦è½¬æ¢...")
        
        for file_path in files:
            try:
                result = self.convert_file(file_path)
                if result:
                    converted_files.append(result)
                else:
                    failed_files.append(file_path)
            except Exception as e:
                print(f"âŒ è½¬æ¢å¤±è´¥: {file_path.name} - {e}")
                failed_files.append(file_path)
        
        print(f"\nğŸ“Š è½¬æ¢ç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸ: {len(converted_files)} ä¸ªæ–‡ä»¶")
        print(f"âŒ å¤±è´¥: {len(failed_files)} ä¸ªæ–‡ä»¶")
        
        if failed_files:
            print(f"\nå¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
            for file_path in failed_files:
                print(f"  - {file_path}")
        
        return converted_files, failed_files


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ–‡æ¡£è½¬æ¢å·¥å…·ï¼šå°† DOC/PDF è½¬æ¢ä¸º Markdown')
    parser.add_argument('input', help='è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('-o', '--output', default='converted_markdown', 
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: converted_markdown)')
    parser.add_argument('-r', '--recursive', action='store_true', 
                       help='é€’å½’å¤„ç†å­ç›®å½•')
    
    args = parser.parse_args()
    
    converter = DocumentConverter(args.output)
    
    input_path = Path(args.input)
    
    if input_path.is_file():
        # è½¬æ¢å•ä¸ªæ–‡ä»¶
        converter.convert_file(input_path)
    elif input_path.is_dir():
        # æ‰¹é‡è½¬æ¢ç›®å½•
        converter.batch_convert(input_path, recursive=args.recursive)
    else:
        print(f"è·¯å¾„ä¸å­˜åœ¨: {input_path}")


if __name__ == "__main__":
    main()